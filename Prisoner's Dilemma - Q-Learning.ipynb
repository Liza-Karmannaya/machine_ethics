{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prisoners Dilemma - working solution\n",
    "\n",
    "1. Run 10 games between 2 agents, using Tit for Tat strategy - see previous notebook \n",
    "2. Run 10 games between 5 agents? \n",
    "3. add Q-learning - learn the dominant strategy \n",
    "4. How to add something like social norm or morality to this? \n",
    "\ta. Add a player caring about how many years another player spends in jail \n",
    "\tb. Add trust? \n",
    "    c. Add player fearing retribution for confessing and testifying \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Run 10 games between 2 agents, using Q-Learning to learn optimal strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code based on https://subversion.american.edu/aisaac/notes/pdsim.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import itertools \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_pairs(mylist): \n",
    "  # Generate all possible non-repeating pairs \n",
    "  pairs = list(itertools.combinations(mylist, 2)) \n",
    " \n",
    "  # Randomly shuffle these pairs \n",
    "  random.shuffle(pairs) \n",
    "  return pairs \n",
    "\n",
    "def mean(seq):  #simplest computation of mean\n",
    "    \"\"\"Return mean of values in `seq`.\"\"\"\n",
    "    n = len(seq)\n",
    "    return sum(seq)/float(n)\n",
    "\n",
    "def transpose(seqseq): #simple 2-dimensional transpose\n",
    "    \"\"\"Return transpose of `seqseq`.\"\"\"\n",
    "    return zip(*seqseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wil be using two objects (classes) - a Game and a Player: \n",
    "\n",
    "Game\n",
    "- Data: players, payoffmat, history, opponents\n",
    "- Methods: run, payoff\n",
    "\n",
    "Player\n",
    "- Data: playertype, games_player, players_played\n",
    "- Methods: get_last_move, make_own_move, record, reset\n",
    "\n",
    "An action is selected between “defection” (represented by True or integer 1) or “cooperation” (represented by False or integer 0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below illustrates the resulting interdependencies between objects when a game asks a player for a move. As part of selecting a move, the player first fetches the opponent's last move from the game. Once the player has this last move, it computes a move and returns it to the game that asked for it.\n",
    "\n",
    "|                Game               |              Player                       |\n",
    "|:---------------------------------:|:-----------------------------------------:|\n",
    "| 1. request move from Player       |                                           |                                 |\n",
    "|                                   | 2. start generating move                  |                                 |\n",
    "|                                   | 3. request opponent's last move           |\n",
    "|                                   | 4. compute opponent's last move by looking into the Game's in history |     |\n",
    "|                                   | 5. compute new move based on last move + the strategy                      |\n",
    "|                                   | 6. return new move to Game                |                                 |\n",
    "| 7. compute payoffs based on pair of moves        |                                           |                                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, player1, player2, payoffmat):\n",
    "        # initialize instance attributes\n",
    "        self.players = [ player1, player2 ]\n",
    "        self.payoffmat = payoffmat\n",
    "        self.history = list() #TO DO make this a circular array / queue instead \n",
    "        self.opponents = {player1:player2, player2:player1}\n",
    "    def run(self, game_iter=4):\n",
    "        # unpack the two players\n",
    "        player1, player2 = self.players\n",
    "        # each iteration, get new moves and append these to history\n",
    "        for iteration in range(game_iter):\n",
    "            #request move from player - use methods from the Player object\n",
    "            newmoves = player1.make_own_move(self), player2.make_own_move(self) \n",
    "            self.history.append(newmoves) #append pair of moves to the history attritbute of this game \n",
    "        # prompt players to record the game played (i.e., 'self') - ???? \n",
    "        player1.record(self); player2.record(self) #use methods from the Player object\n",
    "    def payoff(self):\n",
    "        # unpack the two players\n",
    "        player1, player2 = self.players #note we need to define these again from the __init__ method\n",
    "        # generate player-payoff pairs for each pair of moves (i.e. for each game iteration)\n",
    "        payoffs = (self.payoffmat[m1][m2] for (m1,m2) in self.history)\n",
    "        # transpose to get a payoff sequence for each player\n",
    "        pay1, pay2 = transpose(payoffs) # ????\n",
    "        # return a mapping of each player to its mean payoff\n",
    "        #return { player1:mean(pay1), player2:mean(pay2) }\n",
    "        return { player1:(pay1), player2:(pay2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, strategy):\n",
    "        self.p_cdi=(0,1,0.5) \n",
    "        #a tuple containing: \n",
    "        # (p(D) if opponent cooperates, \n",
    "        # p(C) if opponent cooperates, \n",
    "        # p(D) of defecting in the first move)\n",
    "        \n",
    "        # (p(C) if opponent defects, \n",
    "        # p(D) if opponent defects, \n",
    "        # p(D) of defecting in the first move)\n",
    "        \n",
    "        # (p(opposite move to opponent), \n",
    "        # p(same move as opponent), \n",
    "        # p(D) of defecting in the first move)\n",
    "        \n",
    "        self.reset() #defined below\n",
    "        self.strategy = strategy\n",
    "    def reset(self): \n",
    "        ''' assign empty lists to the player's games_played and players_played attributes. These attributes can \n",
    "        provide a player with “memory”, which can be augmented each time the player's record method is called.'''\n",
    "        self.games_played = list()   #empty list\n",
    "        self.players_played = list()  #empty list\n",
    "    def get_last_move(self, game):\n",
    "        ''' get opponent and learn their last move '''\n",
    "        opponent = game.opponents[self]\n",
    "        if game.history: # if history not empty, return prior move of `opponent`\n",
    "            player_idx = game.players.index(opponent)\n",
    "            last_move = game.history[-1][player_idx]\n",
    "        else:\n",
    "            last_move = None\n",
    "        return last_move\n",
    "    def make_own_move(self, game):\n",
    "        \n",
    "        if self.strategy == 'random':\n",
    "            return random.uniform(0,1) < 0.5\n",
    "        \n",
    "        else:\n",
    "            '''respond to opponent's last move using a reactive strategy based on 1 last move of the opponent'''\n",
    "            last_move = self.get_last_move(game)  \n",
    "            \n",
    "            if self.strategy == 'TitForTat': \n",
    "                if last_move is None: #if this is the initial move\n",
    "                    p_defect = self.p_cdi[-1]\n",
    "                else:\n",
    "                    p_defect = self.p_cdi[last_move]\n",
    "                return random.uniform(0,1) < p_defect\n",
    "        \n",
    "            elif self.strategy == 'Q-Learning greedy':\n",
    "                if last_move is None: #if this is the initial move\n",
    "                    p_defect = self.p_cdi[-1]\n",
    "                    return random.uniform(0,1) < p_defect\n",
    "                else:\n",
    "                    optimal_policy = list(np.argmax(Q_values, axis=1)) \n",
    "                    # store optimal action for that state(i.e. opponent's last_move), based on Q-Learning results\n",
    "                    return optimal_policy[last_move] > 0.5 #return 1 if last_move==True (=defect)\n",
    "        \n",
    "    def record(self, game):\n",
    "        self.games_played.append(game)\n",
    "        opponent = game.opponents[self]\n",
    "        self.players_played.append(opponent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy = list(np.argmax(Q_values, axis=1)) \n",
    "# store optimal action for that state(i.e. opponent's last_move), based on Q-Learning results\n",
    "\n",
    "optimal_policy[player1.get_last_move(game)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player1.get_last_move(game)\n",
    "#opponent cooperated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,0][player1.get_last_move(game)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test)[player1.get_last_move(game)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (5, 0))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = transpose(PAYOFFMAT)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 5), (1, 1))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run game between 2 agents only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player1 payoff:  1.9\n",
      "Player2 payoff:  3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizakarmannaya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    }
   ],
   "source": [
    "## GAME: CDIGame with SimplePlayer\n",
    "# create a payoff matrix and two players\n",
    "PAYOFFMAT = [ [(3,3),(0,5)] , [(5,0),(1,1)] ]\n",
    "#PAYOFFMAT = [ [(-1,-1),(-3,0)] , [(0,-3),(-2,-2)] ]\n",
    "player1 = Player(strategy='Q-Learning greedy')\n",
    "player2 = Player(strategy='random')\n",
    "\n",
    "# create and run the game\n",
    "game = Game(player1, player2, PAYOFFMAT)\n",
    "game.run(10)\n",
    "# retrieve and print the payoffs\n",
    "payoffs = game.payoff()\n",
    "print(\"Player1 payoff: \", mean(payoffs[player1]))\n",
    "print(\"Player2 payoff: \", mean(payoffs[player2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(True, True),\n",
       " (False, False),\n",
       " (False, False),\n",
       " (False, False),\n",
       " (False, False),\n",
       " (False, False),\n",
       " (False, True),\n",
       " (False, True),\n",
       " (False, True),\n",
       " (False, False)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run game between >2 players, a pair at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GAME: CDIGame with SimplePlayer\n",
    "# create a payoff matrix and two players \n",
    "PAYOFFMAT = [ [(3,3),(0,5)] , [(5,0),(1,1)] ]\n",
    "#PAYOFFMAT = [ [(-1,-1),(-3,0)] , [(0,-3),(-2,-2)] ]\n",
    "\n",
    "def run_one_game(player1, player2): \n",
    "    game = Game(player1, player2, PAYOFFMAT)\n",
    "    game.run(10)\n",
    "    # retrieve and print the payoffs\n",
    "    payoffs = game.payoff()\n",
    "    \n",
    "    print(\"Player1 payoff: \", mean(payoffs[player1]))\n",
    "    print(\"Player2 payoff: \", mean(payoffs[player2]))\n",
    "    \n",
    "    return game\n",
    "    \n",
    "\n",
    "def run_ipd_n_players(n=2): #default at least two players \n",
    "    player_names = []\n",
    "    for i in range(1,n+1):\n",
    "        name = 'player' + str(i) \n",
    "        player_names.append(name)\n",
    "    player_objects = [Player(strategy='TitForTat') for name in player_names]\n",
    "    \n",
    "    pairs_of_players = get_random_pairs(player_objects)\n",
    "    \n",
    "    i=0\n",
    "    games_history = [] \n",
    "    for pair in pairs_of_players: \n",
    "        i+=1\n",
    "        print(f'Game {i} betwen: {pair}')\n",
    "        game = run_one_game(pair[0], pair[1])\n",
    "        games_history.append(game)\n",
    "    \n",
    "    return games_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 1 betwen: (<__main__.Player object at 0x7fe4475ee4d0>, <__main__.Player object at 0x7fe4475ee390>)\n",
      "Player1 payoff:  2.5\n",
      "Player2 payoff:  2.5\n",
      "Game 2 betwen: (<__main__.Player object at 0x7fe4475ee4d0>, <__main__.Player object at 0x7fe4475eeed0>)\n",
      "Player1 payoff:  2.5\n",
      "Player2 payoff:  2.5\n",
      "Game 3 betwen: (<__main__.Player object at 0x7fe4475eec90>, <__main__.Player object at 0x7fe4475eeed0>)\n",
      "Player1 payoff:  2.5\n",
      "Player2 payoff:  2.5\n",
      "Game 4 betwen: (<__main__.Player object at 0x7fe4475eec90>, <__main__.Player object at 0x7fe4475ee4d0>)\n",
      "Player1 payoff:  2.5\n",
      "Player2 payoff:  2.5\n",
      "Game 5 betwen: (<__main__.Player object at 0x7fe4475ee390>, <__main__.Player object at 0x7fe4475ee410>)\n",
      "Player1 payoff:  1.0\n",
      "Player2 payoff:  1.0\n",
      "Game 6 betwen: (<__main__.Player object at 0x7fe4475eec90>, <__main__.Player object at 0x7fe4475ee410>)\n",
      "Player1 payoff:  3.0\n",
      "Player2 payoff:  3.0\n",
      "Game 7 betwen: (<__main__.Player object at 0x7fe4475eeed0>, <__main__.Player object at 0x7fe4475ee410>)\n",
      "Player1 payoff:  1.0\n",
      "Player2 payoff:  1.0\n",
      "Game 8 betwen: (<__main__.Player object at 0x7fe4475ee4d0>, <__main__.Player object at 0x7fe4475ee410>)\n",
      "Player1 payoff:  1.0\n",
      "Player2 payoff:  1.0\n",
      "Game 9 betwen: (<__main__.Player object at 0x7fe4475eec90>, <__main__.Player object at 0x7fe4475ee390>)\n",
      "Player1 payoff:  2.5\n",
      "Player2 payoff:  2.5\n",
      "Game 10 betwen: (<__main__.Player object at 0x7fe4475ee390>, <__main__.Player object at 0x7fe4475eeed0>)\n",
      "Player1 payoff:  1.0\n",
      "Player2 payoff:  1.0\n"
     ]
    }
   ],
   "source": [
    "games_history = run_ipd_n_players(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'history',\n",
       " 'opponents',\n",
       " 'payoff',\n",
       " 'payoffmat',\n",
       " 'players',\n",
       " 'run']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(games_history[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent with Q-Learning \n",
    "\n",
    "1. explore the environment \n",
    "2. gradually improve its estimates of Q-values\n",
    "3. choose optimal policy (e.g. greedy policy with the highest q-value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state = (prev own action, prev opponent action).\n",
    "Therefore we can define one-step markov matrix as four probabilities: P(D'|CC), P(D'|CD), P(D'|DC), P(D'|DD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://github.com/ageron/handson-ml2/blob/master/18_reinforcement_learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTEAD: state = single previous action from the opponent; state 0 = opponent defected in the last move; state 1 = opponent Cooperated in the last move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#states possible: opponent cooperated; opponent defected in previous move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probabilities = [ # shape=[s, a, s']\n",
    "#        [[1, 0], [0, 1]],\n",
    "#        [[1, 0], [0, 1]]]\n",
    "    \n",
    "        [[0.5, 0.5], [0.5, 0.5]],\n",
    "        [[0.5, 0.5], [0.5, 0.5]]]\n",
    "\n",
    "\n",
    "\n",
    "#[state(=opponent_prev_move), agent_action] = [CC, CD, DC, DD]\n",
    "\n",
    "#rewards = [ # shape=[s, a, s']\n",
    "#        [[-1, -1], [-3, 0]],\n",
    "#        [[0, -3], [-2, -2]]]\n",
    "\n",
    "rewards = [ # shape=[s, a, s']\n",
    "    [[3,3], [0,5]], \n",
    "    [[5,0], [1,1]]]\n",
    "\n",
    "possible_actions = [[0, 1], [0, 1]] #C,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[3, 3], [0, 5]], [[5, 0], [1, 1]]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, action):\n",
    "    '''function to interact with the environment (i.e. the game).\n",
    "    It takes a state and action as input and computes reward and next state as output.'''\n",
    "    probas = transition_probabilities[state][action]\n",
    "    next_state = np.random.choice([0, 1], p=probas)\n",
    "    #next_state = np.random.choice([0, 1])\n",
    "    reward = rewards[state][action][next_state]\n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test that the step function works correctly \n",
    "test_next_state, test_reward = step(0,0) #if state (opponent's prev move) = C & my action = D\n",
    "test_next_state, test_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration_policy(state):\n",
    "    return np.random.choice(possible_actions[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: 0, possible actions: [0, 1]\n",
      "state: 1, possible actions: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "for state, actions in enumerate(possible_actions):\n",
    "    print(f'state: {state}, possible actions: {actions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "Q_values = np.full((2, 2), -np.inf)\n",
    "for state, actions in enumerate(possible_actions):\n",
    "    Q_values[state][actions] = 0\n",
    "\n",
    "alpha0 = 0.3 # initial learning rate\n",
    "decay = 0.005 # learning rate decay\n",
    "gamma = 0.90 # discount factor\n",
    "state = 0 # initial state\n",
    "history2 = [] # Not shown in the book\n",
    "\n",
    "for iteration in range(10000):\n",
    "    history2.append(Q_values.copy()) # Not shown\n",
    "    action = exploration_policy(state)\n",
    "    next_state, reward = step(state, action)\n",
    "    next_value = np.max(Q_values[next_state]) # greedy policy at the next step\n",
    "    alpha = alpha0 / (1 + iteration * decay)\n",
    "    Q_values[state, action] *= 1 - alpha\n",
    "    Q_values[state, action] += alpha * (reward + gamma * next_value) # -Q_values[state, action]) #is the final term needed??\n",
    "    state = next_state\n",
    "\n",
    "history2 = np.array(history2) # Not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.8184048 , 27.13461633],\n",
       "       [27.26617522, 25.82949414]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Q_values, axis=1) # optimal action for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_values = np.full((2, 2), -np.inf)\n",
    "for state, actions in enumerate(possible_actions):\n",
    "    Q_values[state][actions] = 0\n",
    "    \n",
    "history1 = [] # Not shown in the book (for the figure below)\n",
    "for iteration in range(50):\n",
    "    Q_prev = Q_values.copy()\n",
    "    history1.append(Q_prev) # Not shown\n",
    "    for s in range(2):\n",
    "        for a in possible_actions[s]:\n",
    "            Q_values[s, a] = np.sum([\n",
    "                    transition_probabilities[s][a][sp]\n",
    "                    * (rewards[s][a][sp] + gamma * np.max(Q_prev[sp]))\n",
    "                for sp in range(2)])\n",
    "\n",
    "history1 = np.array(history1) # Not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.59252354, 27.09252354],\n",
       "       [27.09252354, 25.59252354]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_Q_value = history1[-1, 0, 0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "axes[0].set_ylabel(\"Q-Value$(s_0, a_0)$\", fontsize=14)\n",
    "axes[0].set_title(\"Q-Value Iteration\", fontsize=14)\n",
    "axes[1].set_title(\"Q-Learning\", fontsize=14)\n",
    "for ax, width, history in zip(axes, (50, 10000), (history1, history2)):\n",
    "    ax.plot([0, width], [true_Q_value, true_Q_value], \"k--\")\n",
    "    ax.plot(np.arange(width), history[:, 0, 0], \"b-\", linewidth=2)\n",
    "    ax.set_xlabel(\"Iterations\", fontsize=14)\n",
    "    ax.axis([0, width, 0, 34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation showed that alpha=0.05 was too small - it never learnt the true Q-value.  0.1 also never converges to the actual Q-value. I've gone ahead with a learning rate of 0.3 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
